{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6260a616",
   "metadata": {},
   "source": [
    "## Multi Class Classifier\n",
    "**Task**: Create a multi-classifier that if a delay has occured, it will predict what is the cause of the delay based off the duration of the delay. \n",
    "\n",
    "Steps:\n",
    "- Generating training set from features developed in previous Features Engineering notebook. **Note**: This notebook discusses the features engineering process. Find details about feature enginering in [Features_Engineering](Features_Engineering.ipynb)\n",
    "\n",
    "- Train and fit models.\n",
    "\n",
    "Models tested:\n",
    "\n",
    "Logistic Regression.\n",
    "Random Forest Classifier\n",
    "Naive Bayes Biomi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed89ae5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1839bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the full dataset\n",
    "# (note that flights_train is not available in github due to size. only in local repository)\n",
    "chunk = pd.read_csv('../datasets/flights_train_set.csv', \n",
    "#                     usecols = usecols, \n",
    "                    chunksize=1000000, \n",
    "                    low_memory=False)\n",
    "df_full = pd.concat(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b485955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing processing files \n",
    "import sys\n",
    "sys.path.insert(0, '../py_scripts/')\n",
    "from dataset_processing import *\n",
    "from feature_generation_for_multiclass import *\n",
    "from training_and_testing_prep import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1182b6",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6259a36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_full.head(2)\n",
    "df_full.drop(columns = 'Unnamed: 0', inplace=True)\n",
    "df_full.head(2)\n",
    "df_full_ = df_full.copy() # saving a copy to use for training later "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07010172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(            fl_date mkt_unique_carrier branded_code_share mkt_carrier  \\\n",
       " 0        2018-07-14                 NK                 NK          NK   \n",
       " 9        2018-07-14                 NK                 NK          NK   \n",
       " 10       2018-07-14                 NK                 NK          NK   \n",
       " 15       2018-07-14                 NK                 NK          NK   \n",
       " 16       2018-07-14                 NK                 NK          NK   \n",
       " ...             ...                ...                ...         ...   \n",
       " 12015537 2018-07-14                 AA       AA_CODESHARE          AA   \n",
       " 12015544 2018-07-14                 NK                 NK          NK   \n",
       " 12015547 2018-07-14                 NK                 NK          NK   \n",
       " 12015548 2018-07-14                 NK                 NK          NK   \n",
       " 12015553 2018-07-14                 NK                 NK          NK   \n",
       " \n",
       "           mkt_carrier_fl_num op_unique_carrier tail_num  op_carrier_fl_num  \\\n",
       " 0                        424                NK   N684NK                424   \n",
       " 9                        441                NK   N673NK                441   \n",
       " 10                       442                NK   N673NK                442   \n",
       " 15                       452                NK   N506NK                452   \n",
       " 16                       456                NK   N659NK                456   \n",
       " ...                      ...               ...      ...                ...   \n",
       " 12015537                3654                MQ   N644AE               3654   \n",
       " 12015544                 388                NK   N668NK                388   \n",
       " 12015547                 403                NK   N621NK                403   \n",
       " 12015548                 403                NK   N621NK                403   \n",
       " 12015553                 409                NK   N649NK                409   \n",
       " \n",
       "           origin_airport_id origin origin_city_name  dest_airport_id dest  \\\n",
       " 0                     12892    LAX  Los Angeles, CA            13487  MSP   \n",
       " 9                     13930    ORD      Chicago, IL            14747  SEA   \n",
       " 10                    14747    SEA      Seattle, WA            13930  ORD   \n",
       " 15                    13495    MSY  New Orleans, LA            10397  ATL   \n",
       " 16                    12889    LAS    Las Vegas, NV            13930  ORD   \n",
       " ...                     ...    ...              ...              ...  ...   \n",
       " 12015537              11637    FAR        Fargo, ND            13930  ORD   \n",
       " 12015544              11433    DTW      Detroit, MI            11697  FLL   \n",
       " 12015547              10397    ATL      Atlanta, GA            11697  FLL   \n",
       " 12015548              12892    LAX  Los Angeles, CA            10397  ATL   \n",
       " 12015553              13930    ORD      Chicago, IL            11697  FLL   \n",
       " \n",
       "                dest_city_name  crs_dep_time  dep_time  dep_delay  taxi_out  \\\n",
       " 0             Minneapolis, MN          1828    1834.0        6.0      17.0   \n",
       " 9                 Seattle, WA          2034    2203.0       89.0      15.0   \n",
       " 10                Chicago, IL          2354     120.0       86.0       9.0   \n",
       " 15                Atlanta, GA           640     634.0       -6.0      26.0   \n",
       " 16                Chicago, IL            50     106.0       16.0      23.0   \n",
       " ...                       ...           ...       ...        ...       ...   \n",
       " 12015537          Chicago, IL           554     619.0       25.0      11.0   \n",
       " 12015544  Fort Lauderdale, FL          1907    1912.0        5.0      12.0   \n",
       " 12015547  Fort Lauderdale, FL          1915    2031.0       76.0      12.0   \n",
       " 12015548          Atlanta, GA          1049    1042.0       -7.0      34.0   \n",
       " 12015553  Fort Lauderdale, FL           515     653.0       98.0      13.0   \n",
       " \n",
       "           taxi_in  crs_arr_time  arr_time  arr_delay  cancelled  \\\n",
       " 0             5.0          2359    2358.0       -1.0          0   \n",
       " 9            12.0          2254      23.0       89.0          0   \n",
       " 10           18.0           549     707.0       78.0          0   \n",
       " 15           13.0           912     919.0        7.0          0   \n",
       " 16           20.0           624     705.0       41.0          0   \n",
       " ...           ...           ...       ...        ...        ...   \n",
       " 12015537     25.0           750     828.0       38.0          0   \n",
       " 12015544      7.0          2203    2158.0       -5.0          0   \n",
       " 12015547      6.0          2111    2213.0       62.0          0   \n",
       " 12015548     13.0          1825    1912.0       47.0          0   \n",
       " 12015553     16.0           916    1054.0       98.0          0   \n",
       " \n",
       "           crs_elapsed_time  actual_elapsed_time  air_time  flights  distance  \\\n",
       " 0                    211.0                204.0     182.0        1      1535   \n",
       " 9                    260.0                260.0     233.0        1      1721   \n",
       " 10                   235.0                227.0     200.0        1      1721   \n",
       " 15                    92.0                105.0      66.0        1       425   \n",
       " 16                   214.0                239.0     196.0        1      1514   \n",
       " ...                    ...                  ...       ...      ...       ...   \n",
       " 12015537             116.0                129.0      93.0        1       557   \n",
       " 12015544             176.0                166.0     147.0        1      1127   \n",
       " 12015547             116.0                102.0      84.0        1       581   \n",
       " 12015548             276.0                330.0     283.0        1      1947   \n",
       " 12015553             181.0                181.0     152.0        1      1182   \n",
       " \n",
       "           carrier_delay  weather_delay  nas_delay  security_delay  \\\n",
       " 0                   0.0            0.0        0.0             0.0   \n",
       " 9                   0.0            0.0       89.0             0.0   \n",
       " 10                  0.0            0.0       78.0             0.0   \n",
       " 15                  0.0            0.0        0.0             0.0   \n",
       " 16                  0.0            0.0       25.0             0.0   \n",
       " ...                 ...            ...        ...             ...   \n",
       " 12015537           25.0            0.0       13.0             0.0   \n",
       " 12015544            0.0            0.0        0.0             0.0   \n",
       " 12015547            0.0            0.0       62.0             0.0   \n",
       " 12015548            0.0            0.0       47.0             0.0   \n",
       " 12015553           98.0            0.0        0.0             0.0   \n",
       " \n",
       "           late_aircraft_delay  isDelay   target_delay  isCraft  isCarrier  \\\n",
       " 0                         0.0      1.0  carrier_delay        0          1   \n",
       " 9                         0.0      1.0      nas_delay        0          0   \n",
       " 10                        0.0      1.0      nas_delay        0          0   \n",
       " 15                        0.0      1.0  carrier_delay        0          1   \n",
       " 16                       16.0      1.0      nas_delay        0          0   \n",
       " ...                       ...      ...            ...      ...        ...   \n",
       " 12015537                  0.0      1.0  carrier_delay        0          1   \n",
       " 12015544                  0.0      1.0  carrier_delay        0          1   \n",
       " 12015547                  0.0      1.0      nas_delay        0          0   \n",
       " 12015548                  0.0      1.0      nas_delay        0          0   \n",
       " 12015553                  0.0      1.0  carrier_delay        0          1   \n",
       " \n",
       "           dep_hour  arr_hour  branded_share  fl_month  isWeather  isSecurity  \\\n",
       " 0               18        24              0         7          0           0   \n",
       " 9               20        23              0         7          0           0   \n",
       " 10              24         5              0         7          0           0   \n",
       " 15               6         9              0         7          0           0   \n",
       " 16               0         6              0         7          0           0   \n",
       " ...            ...       ...            ...       ...        ...         ...   \n",
       " 12015537         6         8              1         7          0           0   \n",
       " 12015544        19        22              0         7          0           0   \n",
       " 12015547        19        21              0         7          0           0   \n",
       " 12015548        10        18              0         7          0           0   \n",
       " 12015553         5         9              0         7          0           0   \n",
       " \n",
       "           holidate  fl_dayofweek  \n",
       " 0                0             5  \n",
       " 9                0             5  \n",
       " 10               0             5  \n",
       " 15               0             5  \n",
       " 16               0             5  \n",
       " ...            ...           ...  \n",
       " 12015537         0             5  \n",
       " 12015544         0             5  \n",
       " 12015547         0             5  \n",
       " 12015548         0             5  \n",
       " 12015553         0             5  \n",
       " \n",
       " [5299551 rows x 45 columns],\n",
       "           dep_delay  arr_delay   isCraft  isCarrier\n",
       " tail_num                                           \n",
       " 215NV          13.0       14.0  0.217772   0.655820\n",
       " 216NV          13.0       15.0  0.218301   0.626144\n",
       " 217NV          12.0       14.0  0.230488   0.654878\n",
       " 218NV          13.0       15.0  0.231707   0.641463\n",
       " 219NV          14.0       15.0  0.217274   0.642375\n",
       " ...             ...        ...       ...        ...\n",
       " N999DN          8.0        6.0  0.113424   0.764828\n",
       " N999FR         15.0       26.0  0.285714   0.428571\n",
       " N999JB         12.5       14.0  0.209677   0.677419\n",
       " N999JQ         17.0       14.0  0.208469   0.638436\n",
       " SS25           23.0       29.0  0.000000   1.000000\n",
       " \n",
       " [6478 rows x 4 columns],\n",
       "                    dep_delay  carrier_delay  late_aircraft_delay   isCraft  \\\n",
       " tail_num dep_hour                                                            \n",
       " 215NV    6               5.0            0.0                  0.0  0.000000   \n",
       "          7               5.0            0.0                  0.0  0.000000   \n",
       "          8               1.5            0.0                  0.0  0.000000   \n",
       "          9              11.0            0.0                  0.0  0.138889   \n",
       "          10             15.0            0.0                  0.0  0.127273   \n",
       " ...                      ...            ...                  ...       ...   \n",
       " N999JQ   22             30.0            1.0                 12.0  0.416667   \n",
       "          23             32.0            0.0                  0.0  0.357143   \n",
       "          24             27.0            0.0                  0.0  0.333333   \n",
       " SS25     9              23.0           21.0                  0.0  0.000000   \n",
       "          17             23.0           23.0                  0.0  0.000000   \n",
       " \n",
       "                    isCarrier  \n",
       " tail_num dep_hour             \n",
       " 215NV    6          0.868852  \n",
       "          7          0.727273  \n",
       "          8          0.722222  \n",
       "          9          0.722222  \n",
       "          10         0.709091  \n",
       " ...                      ...  \n",
       " N999JQ   22         0.375000  \n",
       "          23         0.500000  \n",
       "          24         0.666667  \n",
       " SS25     9          1.000000  \n",
       "          17         1.000000  \n",
       " \n",
       " [123804 rows x 5 columns],\n",
       "                    arr_delay  carrier_delay  late_aircraft_delay   isCraft  \\\n",
       " tail_num arr_hour                                                            \n",
       " 215NV    0              -2.0            0.0                  0.0  0.000000   \n",
       "          7               7.0            3.5                  0.0  0.000000   \n",
       "          8               8.0            0.0                  0.0  0.000000   \n",
       "          9              10.0            0.0                  0.0  0.027778   \n",
       "          10              9.0            0.0                  0.0  0.000000   \n",
       " ...                      ...            ...                  ...       ...   \n",
       " N999JQ   22             20.5            0.0                  0.0  0.147059   \n",
       "          23             47.5            0.0                  0.0  0.300000   \n",
       "          24            161.0            2.0                159.0  1.000000   \n",
       " SS25     13             21.0           21.0                  0.0  0.000000   \n",
       "          21             37.0           23.0                  0.0  0.000000   \n",
       " \n",
       "                    isCarrier  \n",
       " tail_num arr_hour             \n",
       " 215NV    0          1.000000  \n",
       "          7          0.500000  \n",
       "          8          0.821429  \n",
       "          9          0.777778  \n",
       "          10         0.769231  \n",
       " ...                      ...  \n",
       " N999JQ   22         0.588235  \n",
       "          23         0.400000  \n",
       "          24         0.000000  \n",
       " SS25     13         1.000000  \n",
       "          21         1.000000  \n",
       " \n",
       " [133250 rows x 5 columns],\n",
       "                                               dep_delay  arr_delay  \\\n",
       " op_unique_carrier branded_share fl_dayofweek                         \n",
       " 9E                1             0                  16.0       17.0   \n",
       "                                 1                  14.0       17.0   \n",
       "                                 2                  13.0       15.0   \n",
       "                                 3                  14.0       16.0   \n",
       "                                 4                  15.0       17.0   \n",
       " ...                                                 ...        ...   \n",
       " ZW                1             2                  11.0       17.0   \n",
       "                                 3                  13.0       18.0   \n",
       "                                 4                  11.0       17.0   \n",
       "                                 5                  13.0       17.0   \n",
       "                                 6                  13.0       19.0   \n",
       " \n",
       "                                               carrier_delay  \\\n",
       " op_unique_carrier branded_share fl_dayofweek                  \n",
       " 9E                1             0                       0.0   \n",
       "                                 1                       0.0   \n",
       "                                 2                       0.0   \n",
       "                                 3                       0.0   \n",
       "                                 4                       0.0   \n",
       " ...                                                     ...   \n",
       " ZW                1             2                       0.0   \n",
       "                                 3                       0.0   \n",
       "                                 4                       0.0   \n",
       "                                 5                       0.0   \n",
       "                                 6                       0.0   \n",
       " \n",
       "                                               late_aircraft_delay  isCarrier  \n",
       " op_unique_carrier branded_share fl_dayofweek                                  \n",
       " 9E                1             0                             0.0   0.590727  \n",
       "                                 1                             0.0   0.587495  \n",
       "                                 2                             0.0   0.602048  \n",
       "                                 3                             0.0   0.590678  \n",
       "                                 4                             0.0   0.578915  \n",
       " ...                                                           ...        ...  \n",
       " ZW                1             2                             0.0   0.598306  \n",
       "                                 3                             0.0   0.584496  \n",
       "                                 4                             0.0   0.607812  \n",
       "                                 5                             0.0   0.614631  \n",
       "                                 6                             0.0   0.588265  \n",
       " \n",
       " [196 rows x 5 columns],\n",
       "                           arr_delay  carrier_delay  nas_delay  \\\n",
       " dest_airport_id fl_month                                        \n",
       " 10135           1              15.0            0.0        0.0   \n",
       "                 2              14.0            0.0        0.0   \n",
       "                 3              11.0            0.0        0.0   \n",
       "                 4              13.0            0.0        0.0   \n",
       "                 5              13.0            0.0        0.0   \n",
       " ...                             ...            ...        ...   \n",
       " 16218           11              7.5            0.0        0.0   \n",
       "                 12             11.5            0.0        0.0   \n",
       " 16869           10             14.0            0.0        0.0   \n",
       "                 11             11.0            0.0        0.0   \n",
       "                 12             22.0            0.0        0.0   \n",
       " \n",
       "                           late_aircraft_delay  weather_delay  security_delay  \\\n",
       " dest_airport_id fl_month                                                       \n",
       " 10135           1                         0.0            0.0             0.0   \n",
       "                 2                         0.0            0.0             0.0   \n",
       "                 3                         0.0            0.0             0.0   \n",
       "                 4                         0.0            0.0             0.0   \n",
       "                 5                         0.0            0.0             0.0   \n",
       " ...                                       ...            ...             ...   \n",
       " 16218           11                        0.0            0.0             0.0   \n",
       "                 12                        0.0            0.0             0.0   \n",
       " 16869           10                        0.0            0.0             0.0   \n",
       "                 11                        0.0            0.0             0.0   \n",
       "                 12                        0.0            0.0             0.0   \n",
       " \n",
       "                           isWeather  isSecurity  \n",
       " dest_airport_id fl_month                         \n",
       " 10135           1          0.025926    0.000000  \n",
       "                 2          0.022026    0.000000  \n",
       "                 3          0.012097    0.000000  \n",
       "                 4          0.019544    0.000000  \n",
       "                 5          0.035971    0.000000  \n",
       " ...                             ...         ...  \n",
       " 16218           11         0.000000    0.000000  \n",
       "                 12         0.000000    0.000000  \n",
       " 16869           10         0.051282    0.000000  \n",
       "                 11         0.045455    0.000000  \n",
       "                 12         0.000000    0.021739  \n",
       " \n",
       " [4403 rows x 8 columns],\n",
       "                             dep_delay  arr_delay  carrier_delay  nas_delay  \\\n",
       " origin_airport_id fl_month                                                   \n",
       " 10135             1              10.0       14.0            0.0        0.0   \n",
       "                   2               9.0       15.0            0.0        0.0   \n",
       "                   3               6.0       15.0            0.0        0.0   \n",
       "                   4               8.0       13.0            0.0        0.0   \n",
       "                   5              12.0       12.0            0.0        0.0   \n",
       " ...                               ...        ...            ...        ...   \n",
       " 16218             11              0.0        6.0            0.0        0.0   \n",
       "                   12              9.0       10.5            0.0        0.0   \n",
       " 16869             10              6.5       10.0            0.0        0.0   \n",
       "                   11             16.5       21.5            0.0        0.0   \n",
       "                   12             19.0       14.0            0.0        0.0   \n",
       " \n",
       "                             late_aircraft_delay  weather_delay  \\\n",
       " origin_airport_id fl_month                                       \n",
       " 10135             1                         0.0            0.0   \n",
       "                   2                         0.0            0.0   \n",
       "                   3                         0.0            0.0   \n",
       "                   4                         0.0            0.0   \n",
       "                   5                         0.0            0.0   \n",
       " ...                                         ...            ...   \n",
       " 16218             11                        0.0            0.0   \n",
       "                   12                        0.0            0.0   \n",
       " 16869             10                        0.0            0.0   \n",
       "                   11                        0.0            0.0   \n",
       "                   12                        0.0            0.0   \n",
       " \n",
       "                             security_delay  isWeather  isSecurity  \n",
       " origin_airport_id fl_month                                         \n",
       " 10135             1                    0.0   0.007634    0.000000  \n",
       "                   2                    0.0   0.018182    0.000000  \n",
       "                   3                    0.0   0.016447    0.000000  \n",
       "                   4                    0.0   0.005970    0.000000  \n",
       "                   5                    0.0   0.022814    0.000000  \n",
       " ...                                    ...        ...         ...  \n",
       " 16218             11                   0.0   0.000000    0.000000  \n",
       "                   12                   0.0   0.000000    0.000000  \n",
       " 16869             10                   0.0   0.000000    0.026316  \n",
       "                   11                   0.0   0.083333    0.033333  \n",
       "                   12                   0.0   0.081967    0.016393  \n",
       " \n",
       " [4407 rows x 9 columns],\n",
       "                                             dep_delay  arr_delay  \\\n",
       " holidate origin_airport_id dest_airport_id                         \n",
       " 0        10135             10397                  5.0       12.0   \n",
       "                            10693                 57.0       63.0   \n",
       "                            11057                  6.0        9.0   \n",
       "                            11433                 11.0       11.0   \n",
       "                            11697                 18.0       22.0   \n",
       " ...                                               ...        ...   \n",
       " 1        16133             14112                111.0      141.0   \n",
       "          16218             11298                 29.0       27.0   \n",
       "                            14107                  4.0       10.0   \n",
       "          16869             11292                 20.0       29.0   \n",
       "                            13487                 21.5       19.5   \n",
       " \n",
       "                                             carrier_delay  nas_delay  \\\n",
       " holidate origin_airport_id dest_airport_id                             \n",
       " 0        10135             10397                      0.0        0.0   \n",
       "                            10693                      0.0        6.0   \n",
       "                            11057                      0.0        0.0   \n",
       "                            11433                      0.0        0.0   \n",
       "                            11697                      0.0        0.0   \n",
       " ...                                                   ...        ...   \n",
       " 1        16133             14112                      0.0       37.0   \n",
       "          16218             11298                      0.0        0.0   \n",
       "                            14107                      0.0        0.0   \n",
       "          16869             11292                      0.0        0.0   \n",
       "                            13487                      0.0        0.0   \n",
       " \n",
       "                                             late_aircraft_delay  \\\n",
       " holidate origin_airport_id dest_airport_id                        \n",
       " 0        10135             10397                            0.0   \n",
       "                            10693                           42.0   \n",
       "                            11057                            0.0   \n",
       "                            11433                            0.0   \n",
       "                            11697                            0.0   \n",
       " ...                                                         ...   \n",
       " 1        16133             14112                          104.0   \n",
       "          16218             11298                            0.0   \n",
       "                            14107                            0.0   \n",
       "          16869             11292                            0.0   \n",
       "                            13487                            0.0   \n",
       " \n",
       "                                             weather_delay  security_delay  \\\n",
       " holidate origin_airport_id dest_airport_id                                  \n",
       " 0        10135             10397                      0.0             0.0   \n",
       "                            10693                      0.0             0.0   \n",
       "                            11057                      0.0             0.0   \n",
       "                            11433                      0.0             0.0   \n",
       "                            11697                      0.0             0.0   \n",
       " ...                                                   ...             ...   \n",
       " 1        16133             14112                      0.0             0.0   \n",
       "          16218             11298                      0.0             0.0   \n",
       "                            14107                      0.0             0.0   \n",
       "          16869             11292                      0.0             0.0   \n",
       "                            13487                      0.0             0.0   \n",
       " \n",
       "                                             isWeather  isSecurity  \n",
       " holidate origin_airport_id dest_airport_id                         \n",
       " 0        10135             10397             0.013011    0.000000  \n",
       "                            10693             0.090909    0.000000  \n",
       "                            11057             0.011257    0.000000  \n",
       "                            11433             0.021739    0.001812  \n",
       "                            11697             0.052632    0.000000  \n",
       " ...                                               ...         ...  \n",
       " 1        16133             14112             0.000000    0.000000  \n",
       "          16218             11298             0.000000    0.000000  \n",
       "                            14107             0.000000    0.000000  \n",
       "          16869             11292             0.047619    0.000000  \n",
       "                            13487             0.250000    0.000000  \n",
       " \n",
       " [13521 rows x 9 columns],\n",
       "                                                 dep_delay  arr_delay  \\\n",
       " origin_airport_id dest_airport_id fl_dayofweek                         \n",
       " 10135             10397           0                   7.0       13.0   \n",
       "                                   1                   4.0       12.0   \n",
       "                                   2                   2.5       15.0   \n",
       "                                   3                   3.0        8.0   \n",
       "                                   4                   6.0        8.0   \n",
       " ...                                                   ...        ...   \n",
       " 16869             13487           2                  24.0       21.0   \n",
       "                                   3                   6.0      -11.0   \n",
       "                                   4                   5.0        0.0   \n",
       "                                   5                  16.0       18.0   \n",
       "                                   6                  11.0       17.5   \n",
       " \n",
       "                                                 carrier_delay  nas_delay  \\\n",
       " origin_airport_id dest_airport_id fl_dayofweek                             \n",
       " 10135             10397           0                       0.0        0.0   \n",
       "                                   1                       0.0        0.0   \n",
       "                                   2                       0.0        0.0   \n",
       "                                   3                       0.0        0.0   \n",
       "                                   4                       0.0        0.0   \n",
       " ...                                                       ...        ...   \n",
       " 16869             13487           2                       0.0        0.0   \n",
       "                                   3                       0.0        0.0   \n",
       "                                   4                       0.0        0.0   \n",
       "                                   5                       0.0        0.0   \n",
       "                                   6                       0.0        0.0   \n",
       " \n",
       "                                                 late_aircraft_delay  \\\n",
       " origin_airport_id dest_airport_id fl_dayofweek                        \n",
       " 10135             10397           0                             0.0   \n",
       "                                   1                             0.0   \n",
       "                                   2                             0.0   \n",
       "                                   3                             0.0   \n",
       "                                   4                             0.0   \n",
       " ...                                                             ...   \n",
       " 16869             13487           2                             0.0   \n",
       "                                   3                             0.0   \n",
       "                                   4                             0.0   \n",
       "                                   5                             0.0   \n",
       "                                   6                             0.0   \n",
       " \n",
       "                                                 weather_delay  security_delay  \\\n",
       " origin_airport_id dest_airport_id fl_dayofweek                                  \n",
       " 10135             10397           0                       0.0             0.0   \n",
       "                                   1                       0.0             0.0   \n",
       "                                   2                       0.0             0.0   \n",
       "                                   3                       0.0             0.0   \n",
       "                                   4                       0.0             0.0   \n",
       " ...                                                       ...             ...   \n",
       " 16869             13487           2                       0.0             0.0   \n",
       "                                   3                       0.0             0.0   \n",
       "                                   4                       0.0             0.0   \n",
       "                                   5                       0.0             0.0   \n",
       "                                   6                       0.0             0.0   \n",
       " \n",
       "                                                 isCarrier  traffic  \n",
       " origin_airport_id dest_airport_id fl_dayofweek                      \n",
       " 10135             10397           0              0.613861      101  \n",
       "                                   1              0.617978       89  \n",
       "                                   2              0.566667       90  \n",
       "                                   3              0.691489       94  \n",
       "                                   4              0.701149       87  \n",
       " ...                                                   ...      ...  \n",
       " 16869             13487           2              0.666667        9  \n",
       "                                   3              0.857143        7  \n",
       "                                   4              0.818182       11  \n",
       "                                   5              0.750000        8  \n",
       "                                   6              0.375000        8  \n",
       " \n",
       " [43385 rows x 9 columns])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_generation(df_full, 0)\n",
    "# this function calls the necessary functions to clean the dataset \n",
    "# and generate the aggregate features for model training\n",
    "# save_features = True saves the files into the local directory, save_features False returns them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4ef96fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_generation (df_full, save_features=0):\n",
    "    \n",
    "    \"\"\"\n",
    "    input: none but df_full = flights_csv full dataset after initial cleaning\n",
    "    and test/train split should already be declared in the notebook.\n",
    "    \n",
    "    generates the aggregate features used for model training\n",
    "    \n",
    "    returns: either returns the dataframes or it saves them to csv\n",
    "    \"\"\"\n",
    "    tmp = preprocessing_dataset(df_full)\n",
    "    \n",
    "\n",
    "    tmp2 = tailnum_delay_taxi_multiclass_params(tmp)\n",
    "    tmp3, tmp4 = tailnum_hourly_delays_multiclass_params(tmp)\n",
    "    tmp5 = carrier_branded_dayofweek_delay_multiclass_params(tmp)\n",
    "    tmp6 = dest_monthly_multiclass_params(tmp)\n",
    "    tmp7 = origin_monthly_multiclass_params(tmp)\n",
    "    tmp8 = holiday_multiclass_params(tmp)\n",
    "    tmp9 = origin_dest_route_dayofweek_multiclass_params(tmp)\n",
    "    \n",
    "    # save to file\n",
    "    if save_features:\n",
    "        tmp2.to_csv('../data/features_tailnum_delay_taxi_multiclass_params.csv')\n",
    "        tmp3.to_csv('../data/features_tailnum_hourly_delays_multiclass_params_dep.csv')\n",
    "        tmp4.to_csv('../data/features_tailnum_hourly_delays_multiclass_params_arr.csv')\n",
    "        tmp5.to_csv('../data/features_carrier_branded_dayofweek_delay_multiclass_params.csv')\n",
    "        tmp6.to_csv('../data/features_dest_monthly_multiclass_params.csv')\n",
    "        tmp7.to_csv('../data/features_origin_monthly_multiclass_params.csv')\n",
    "        tmp8.to_csv('../data/features_holiday_multiclass_params.csv')\n",
    "        tmp9.to_csv('../data/features_origin_dest_route_dayofweek_multiclass_params.csv')\n",
    "        return tmp\n",
    "    else:       \n",
    "        return tmp, tmp2, tmp3, tmp4, tmp5, tmp6, tmp7, tmp8, tmp9\n",
    "        \n",
    "        \n",
    "def preprocessing_dataset(df):\n",
    "    \"\"\"\n",
    "    Input: full dataset or a sample dataset of flights_csv after initial cleaning (check duplicates etc)\n",
    "    returns: clean dataset (no null values) and only records of delayed flights for analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    # cleaning 'arr_delay' and 'dep_delay'\n",
    "    # remove any null values that are left after calling the cleaning function\n",
    "    df = cleaning_delays(df)\n",
    "    df.dropna(subset=['arr_delay', 'dep_delay'], inplace=True) \n",
    "    unused_cols = ['wheels_off', \n",
    "                    'wheels_on',\n",
    "                    'diverted',\n",
    "                    'cancellation_code',\n",
    "                    'dup',\n",
    "                    'first_dep_time',\n",
    "                    'total_add_gtime',\n",
    "                    'longest_add_gtime',\n",
    "                    'no_name']\n",
    "    df = df.drop(columns=unused_cols) # delete unnecessary cols\n",
    "    # column for the target labels\n",
    "    # clean the delay variables, fill with 0, assuming nan delays were 0\n",
    "    delay_cols = ['carrier_delay', 'weather_delay',\n",
    "       'nas_delay', 'security_delay', 'late_aircraft_delay'] \n",
    "    for col in delay_cols:\n",
    "        df[col].fillna(0, inplace=True) \n",
    "    \n",
    "    \n",
    "    # filter out records where there were no delays\n",
    "    df['isDelay'] = df['arr_delay'].apply(lambda x: 1 if x>0 else None)\n",
    "    df['isDepDelay'] = df['dep_delay'].apply(lambda x: 1 if x>0 else None)\n",
    "    df['isDelay'].fillna(df['isDepDelay'], inplace=True)\n",
    "    df.drop(columns=['isDepDelay'], inplace=True)\n",
    "    df.dropna(subset='isDelay', inplace=True)\n",
    "    \n",
    "    # defining the target (y) labels\n",
    "    df['target_delay'] = df[delay_cols].idxmax(axis=1) # returns maximum delay\n",
    "    \n",
    "\n",
    "    \n",
    "    return df\n",
    "    \n",
    "    \n",
    "    \n",
    "def cleaning_delays (df_sample):\n",
    "    \"\"\"input flights csv full dataset or sample data\n",
    "    checks null values for dep_delay and arr_delay \n",
    "    against crs_times and actual times to confirm they are null and not 0s\n",
    "    usually CALLED by preprocessing_dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    # checking for Null values \n",
    "    filter1 = df_sample['dep_delay'].isna()\n",
    "    filter2 = (df_sample['crs_dep_time'] == df_sample['dep_time'])\n",
    "\n",
    "    indices = df_sample[(filter1) & (filter2)].index\n",
    "\n",
    "    for idx in indices:\n",
    "        df_sample.loc[idx,'dep_delay'] = 0\n",
    "    \n",
    "    filter1 = df_sample['arr_delay'].isna()\n",
    "    filter2 = (df_sample['crs_arr_time'] == df_sample['arr_time'])\n",
    "\n",
    "    indices = df_sample[(filter1) & (filter2)].index\n",
    "\n",
    "    for idx in indices:\n",
    "        df_sample.loc[idx,'arr_delay'] = 0\n",
    "        \n",
    "        \n",
    "    return df_sample\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "### All scripts should be run on flights dataset (full or sample) after preprocessing_dataset function.\n",
    "\n",
    "def tailnum_delay_taxi_multiclass_params(df_sample):\n",
    "    \"\"\"\n",
    "    Input: flights csv sample or full dataset AFTER preprocessing_dataset\n",
    "    Aggregates on tail_num\n",
    "    Output: \n",
    "        index / join key: 'tail_num'\n",
    "        columns: aggregated isCraft and isCarrier delays \n",
    "    \"\"\"  \n",
    "    \n",
    "    df_sample['isCraft'] = df_sample['target_delay'].\\\n",
    "                            apply (lambda x: 1 if x == 'late_aircraft_delay' else 0)\n",
    "    df_sample['isCarrier'] = df_sample['target_delay'].\\\n",
    "                            apply (lambda x: 1 if x == 'carrier_delay' else 0)\n",
    "\n",
    "    tailnum_delay_taxi_df = df_sample.groupby('tail_num').agg({'dep_delay': 'median',\n",
    "                                  'arr_delay' : 'median',\n",
    "                                  'isCraft' : 'mean',\n",
    "                                  'isCarrier' : 'mean'      \n",
    "                                  })\n",
    "    return tailnum_delay_taxi_df\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def tailnum_hourly_delays_multiclass_params(df_sample):\n",
    "    \"\"\"\n",
    "    Input: flights csv sample or full dataset AFTER preprocessing_dataset\n",
    "    Aggregates on tail_num and arr_hour and tail_num and dep_hour\n",
    "    Output: 2 dataframes \n",
    "        index / join key: 'tail_num' and arr_hour / dep_hour\n",
    "        columns: median delays\n",
    "    \"\"\"  \n",
    "    df_sample['isCraft'] = df_sample['target_delay'].\\\n",
    "                            apply (lambda x: 1 if x == 'late_aircraft_delay' else 0)\n",
    "    df_sample['isCarrier'] = df_sample['target_delay'].\\\n",
    "                            apply (lambda x: 1 if x == 'carrier_delay' else 0)\n",
    "    \n",
    "    # extract hour and minute from crs_time\n",
    "    df_sample['dep_hour'] = (np.round(df_sample['crs_dep_time'],-2)/100).astype(int)\n",
    "    df_sample['arr_hour'] = (np.round(df_sample['crs_arr_time'],-2)/100).astype(int)\n",
    "    \n",
    "    tailnum_dep_hourly_delays_df = df_sample.groupby(['tail_num', 'dep_hour']).agg({'dep_delay': 'median',\n",
    "                                          'carrier_delay' :  'median',\n",
    "                                          'late_aircraft_delay' :  'median',\n",
    "                                          'isCraft' : 'mean', \n",
    "                                          'isCarrier' : 'mean' })\n",
    "    tailnum_arr_hourly_delays_df = df_sample.groupby(['tail_num', 'arr_hour']).agg({'arr_delay': 'median',\n",
    "                                          'carrier_delay' :  'median',\n",
    "                                          'late_aircraft_delay' :  'median',\n",
    "                                          'isCraft' : 'mean', \n",
    "                                          'isCarrier' : 'mean' })\n",
    "    \n",
    "    return tailnum_dep_hourly_delays_df, tailnum_arr_hourly_delays_df\n",
    "    \n",
    "    \n",
    "def carrier_branded_dayofweek_delay_multiclass_params(df_sample):\n",
    "    \"\"\"\n",
    "    Input: flights csv sample or full dataset AFTER preprocessing_dataset\n",
    "    Aggregates on op_unique_carrier, branded_share, f1_dayofweek\n",
    "    \n",
    "    Output: \n",
    "        index /join key: op_unique_carrier, branded_share, f1_dayofweek\n",
    "        columns: median delays and isCarrier\n",
    "    \"\"\"      \n",
    "    \n",
    "\n",
    "    df_sample['branded_share'] = df_sample['branded_code_share'].apply(lambda x: 1 if len(x)>2 else 0)\n",
    "    df_sample = df_sample.drop(columns = ['branded_code_share'])\n",
    "    \n",
    "    \n",
    "    df_sample['isCarrier'] = df_sample['target_delay'].\\\n",
    "                            apply (lambda x: 1 if x == 'carrier_delay' else 0)\n",
    "\n",
    "\n",
    "    df_sample['fl_date'] = pd.to_datetime(df_sample['fl_date'])\n",
    "    df_sample['fl_dayofweek'] = df_sample['fl_date'].dt.dayofweek\n",
    "    df_sample.drop(columns=['fl_date'], inplace=True)\n",
    "\n",
    "\n",
    "    carrier_df = df_sample.groupby(['op_unique_carrier', 'branded_share', 'fl_dayofweek'])\\\n",
    "                                    .agg({'dep_delay': 'median',\n",
    "                                          'arr_delay' : 'median',\n",
    "                                          'carrier_delay' :  'median',\n",
    "                                          'late_aircraft_delay' :  'median', \n",
    "                                          'isCarrier' : 'mean' })\n",
    "    return carrier_df\n",
    "\n",
    "def dest_monthly_multiclass_params(df_sample):\n",
    "    \"\"\"\n",
    "    Input: flights csv sample or full dataset AFTER preprocessing_dataset\n",
    "    Aggregates on dest_airport_id, fl_month\n",
    "    \n",
    "    Output: 2 dataframes \n",
    "        index / join key: dest_airport_id, fl_month\n",
    "        columns: median delays and isWeather, isSecurity\n",
    "    \"\"\"   \n",
    "\n",
    "    # extract hour and minute from crs_time\n",
    "    df_sample['fl_date'] = pd.to_datetime(df_sample['fl_date'])\n",
    "    df_sample['fl_month'] = df_sample['fl_date'].dt.month\n",
    "    \n",
    "    df_sample['isWeather'] = df_sample['target_delay'].\\\n",
    "                            apply (lambda x: 1 if x == 'weather_delay' else 0)\n",
    "    df_sample['isSecurity'] = df_sample['target_delay'].\\\n",
    "                            apply (lambda x: 1 if x == 'security_delay' else 0)\n",
    "\n",
    "    \n",
    "    dest_monthly_params = df_sample.groupby(['dest_airport_id', 'fl_month']).agg({'arr_delay': 'median',\n",
    "                                  'arr_delay' : 'median',\n",
    "                                  'carrier_delay': 'median',  \n",
    "                                  'nas_delay': 'median', \n",
    "                                  'late_aircraft_delay': 'median',                                    \n",
    "                                  'weather_delay' : 'median',\n",
    "                                  'security_delay' : 'median', \n",
    "                                  'isWeather' : 'mean' , \n",
    "                                  'isSecurity' : 'mean' ,\n",
    "                                                                                  \n",
    "                                  })\n",
    "    \n",
    "    dest_monthly_params.index.to_flat_index()\n",
    "    return dest_monthly_params\n",
    "    \n",
    "def origin_monthly_multiclass_params(df_sample):\n",
    "    \"\"\"\n",
    "    Input: flights csv sample or full dataset AFTER preprocessing_dataset\n",
    "    Aggregates on origin_airport_id, fl_month\n",
    "          \n",
    "    Output: A dataframe\n",
    "        index / join key: 'origin_airport_id', 'fl_month'\n",
    "        columns: median delays and isWeather, isSecurity\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    # extract hour and minute from crs_time\n",
    "    df_sample['fl_date'] = pd.to_datetime(df_sample['fl_date'])\n",
    "    df_sample['fl_month'] = df_sample['fl_date'].dt.month\n",
    "\n",
    "    df_sample['isWeather'] = df_sample['target_delay'].\\\n",
    "                            apply (lambda x: 1 if x == 'weather_delay' else 0)\n",
    "    df_sample['isSecurity'] = df_sample['target_delay'].\\\n",
    "                            apply (lambda x: 1 if x == 'security_delay' else 0)\n",
    "    \n",
    "    origin_monthly_params = df_sample.groupby(['origin_airport_id', 'fl_month']).agg({'dep_delay': 'median',\n",
    "                                  'arr_delay' : 'median',\n",
    "                                  'carrier_delay': 'median',  \n",
    "                                  'nas_delay': 'median', \n",
    "                                  'late_aircraft_delay': 'median',                                    \n",
    "                                  'weather_delay' : 'median',\n",
    "                                  'security_delay' : 'median', \n",
    "                                  'isWeather' : 'mean', \n",
    "                                  'isSecurity' : 'mean',\n",
    "                                  })\n",
    "    \n",
    "    origin_monthly_params.index.to_flat_index()\n",
    "    return origin_monthly_params\n",
    "    \n",
    "def holiday_multiclass_params(df_sample):\n",
    "    \"\"\"\n",
    "    Input: flights csv sample or full dataset AFTER preprocessing_dataset\n",
    "    Aggregates on 'holidate', 'origin_airport_id', 'dest_airport_id'\n",
    "    Output: \n",
    "        Index / join key: 'holidate', 'origin_airport_id', 'dest_airport_id'\n",
    "        columns: median delays,  isWeather isSecurity\n",
    "\n",
    "    \"\"\"\n",
    "       \n",
    "        \n",
    "########################################\n",
    "##  run this if holidays is not available. check the file location first\n",
    "    us_holidays_df = pd.read_csv('../extra/us_holidays.csv')\n",
    "\n",
    "    from datetime import timedelta\n",
    "    holidays = []\n",
    "    for hol in us_holidays_df['date'].values:\n",
    "        holstart = pd.to_datetime(hol) - timedelta(days=3)\n",
    "        holend = pd.to_datetime(hol) + timedelta(days=3)\n",
    "        holidayweek = pd.date_range(holstart, holend)\n",
    "        holidays.extend(holidayweek)\n",
    "#######################\n",
    "    \n",
    "    df_sample['isWeather'] = df_sample['target_delay'].\\\n",
    "                            apply (lambda x: 1 if x == 'weather_delay' else 0)\n",
    "    df_sample['isSecurity'] = df_sample['target_delay'].\\\n",
    "                            apply (lambda x: 1 if x == 'security_delay' else 0)\n",
    "\n",
    "    \n",
    "    # get holidate \n",
    "    df_sample['fl_date'] = pd.to_datetime(df_sample['fl_date'])\n",
    "    df_sample['holidate'] = df_sample['fl_date'].apply(lambda x: 1 if x in holidays else 0)\n",
    "\n",
    "\n",
    "    holiday_params = df_sample.groupby(['holidate', 'origin_airport_id', 'dest_airport_id']).agg({'dep_delay': 'median',\n",
    "                              'arr_delay' : 'median',\n",
    "                              'carrier_delay': 'median',  \n",
    "                              'nas_delay': 'median', \n",
    "                              'late_aircraft_delay': 'median',                                    \n",
    "                              'weather_delay' : 'median',\n",
    "                              'security_delay' : 'median',\n",
    "                              'isWeather' : 'mean', \n",
    "                              'isSecurity' : 'mean',\n",
    "                              })\n",
    "    \n",
    "    return holiday_params\n",
    "        \n",
    "        \n",
    "def origin_dest_route_dayofweek_multiclass_params(df_sample):\n",
    "    \"\"\"\n",
    "    Input: flights csv sample or full dataset AFTER preprocessing_dataset\n",
    "    Aggregates on 'origin_airport_id', 'dest_airport_id', 'fl_dayofweek'\n",
    "    \n",
    "    Output: A dataframe\n",
    "        Index: 'origin_airport_id', 'dest_airport_id', 'fl_dayofweek'\n",
    "        columns: median delays, isCarrier\n",
    "    \"\"\"\n",
    "    \n",
    "    df_sample['isCarrier'] = df_sample['target_delay'].\\\n",
    "                            apply (lambda x: 1 if x == 'carrier_delay' else 0)\n",
    "    \n",
    "    # get dayofweek\n",
    "    df_sample['fl_date'] = pd.to_datetime(df_sample['fl_date'])\n",
    "    df_sample['fl_dayofweek'] = df_sample['fl_date'].dt.dayofweek\n",
    "    # traffic\n",
    "    \n",
    "    params_df = df_sample.groupby(['origin_airport_id', 'dest_airport_id', \n",
    "                                   'fl_dayofweek']).agg({'dep_delay': 'median',\n",
    "                              'arr_delay' : 'median',\n",
    "                              'carrier_delay': 'median',  \n",
    "                              'nas_delay': 'median', \n",
    "                              'late_aircraft_delay': 'median',                                    \n",
    "                              'weather_delay' : 'median',\n",
    "                              'security_delay' : 'median',\n",
    "                              'isCarrier' : 'mean'\n",
    "                              })\n",
    "\n",
    "    params_df['traffic'] = df_sample.groupby(['origin_airport_id', 'dest_airport_id', 'fl_dayofweek']).size()\n",
    "    \n",
    "    \n",
    "    return params_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "139db015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparing_training_df(train_df):\n",
    "    \"\"\"Input: dataset after preprocessing\n",
    "    check extras for  holidays csv\n",
    "    Output: 2 datasets: X and y\n",
    "    \"\"\"\n",
    "\n",
    "    ######################################################\n",
    "    # getting the list of US national holidays\n",
    "    # run this if 'holidays' is not available. check the file location first\n",
    "    try:\n",
    "        us_holidays_df = pd.read_csv('../extra/us_holidays.csv')\n",
    "    except:\n",
    "        filname = input('File location for us_holidays_df')\n",
    "        us_holidays_df = pd.read_csv(filname)\n",
    "\n",
    "    from datetime import timedelta\n",
    "    holidays = []\n",
    "    for hol in us_holidays_df['date'].values:\n",
    "        holstart = pd.to_datetime(hol) - timedelta(days=5)\n",
    "        holend = pd.to_datetime(hol) + timedelta(days=3)\n",
    "        holidayweek = pd.date_range(holstart, holend)\n",
    "        holidays.extend(holidayweek)\n",
    "    #######################################################          \n",
    "\n",
    "\n",
    "    # EDA: column transformations to integrate with the preprocessed feature tables:\n",
    "    # binarize branded share\n",
    "    train_df['branded_share'] = train_df['branded_code_share'].apply(lambda x: 1 if len(x)>2 else 0)\n",
    "    # extract month and day of week and holidate\n",
    "    train_df['fl_date'] = pd.to_datetime(train_df['fl_date'])\n",
    "    train_df['fl_month'] = train_df['fl_date'].dt.month\n",
    "    train_df['fl_dayofweek'] = train_df['fl_date'].dt.dayofweek\n",
    "    train_df['fl_date'] = pd.to_datetime(train_df['fl_date'])\n",
    "    train_df['holidate'] = train_df['fl_date'].apply(lambda x: 1 if x in holidays else 0)\n",
    "\n",
    "    # extract flight hour\n",
    "    train_df['dep_hour'] = (np.round(train_df['crs_dep_time'],-2)/100).astype(int)\n",
    "    train_df['arr_hour'] = (np.round(train_df['crs_arr_time'],-2)/100).astype(int)\n",
    "\n",
    "    # drop irrelevant columns  \n",
    "    train_df.drop(columns = ['mkt_unique_carrier', 'mkt_carrier',\n",
    "                         'mkt_carrier_fl_num',\n",
    "                         'op_carrier_fl_num',\n",
    "                         'origin', 'origin_city_name'],\n",
    "                         inplace=True)\n",
    "\n",
    "    train_df.drop(columns = ['dest', 'dest_city_name',\n",
    "                         'crs_elapsed_time',\n",
    "                         'flights',\n",
    "                         'fl_date',\n",
    "                         'crs_dep_time', 'crs_arr_time',\n",
    "                         'branded_code_share'],\n",
    "                          inplace=True)\n",
    "\n",
    "    delay_cols = ['carrier_delay', 'weather_delay',\n",
    "                   'nas_delay', 'security_delay', 'late_aircraft_delay'] \n",
    "\n",
    "#     # defining the target (y) labels\n",
    "#     df['target'] = df[delay_cols].idxmax(axis=1) # returns maximum delay\n",
    "\n",
    "    # remove delays from dataset\n",
    "    train_df.drop(columns=delay_cols, inplace=True)\n",
    "\n",
    "    train_df.drop(columns = ['dep_time',\n",
    "                       'dep_delay', 'taxi_out', 'taxi_in', 'arr_time',\n",
    "                       'arr_delay', 'cancelled','actual_elapsed_time',\n",
    "                       'air_time', 'isDelay'],\n",
    "                              inplace=True)\n",
    " \n",
    "    ################# calling features tables\n",
    "    \n",
    "    # merging the testing dataset with the features tables of aggregate values\n",
    "    # thereby converting categorical and ordinal columns to continuous values\n",
    "    tmp = train_df\n",
    "    train_df = tmp.merge(features_2, \n",
    "                  left_on=['tail_num'], \n",
    "                  right_on=['tail_num'], how='left').merge(features_3,\n",
    "                  left_on=['tail_num','dep_hour'],\n",
    "                  right_on=['tail_num','dep_hour']).merge(features_4,\n",
    "                  left_on=['tail_num','arr_hour'],\n",
    "                  right_on=['tail_num','arr_hour']).merge(features_5,\n",
    "                  left_on=['op_unique_carrier', 'branded_share', 'fl_dayofweek'], \n",
    "                  right_on=['op_unique_carrier', 'branded_share', 'fl_dayofweek'],\n",
    "                  suffixes=('_', '_carrier')).merge(features_6,\n",
    "                  left_on=['dest_airport_id', 'fl_month'], \n",
    "                  right_on=['dest_airport_id', 'fl_month'],\n",
    "                  suffixes=('_', '_dest')).merge(features_7,\n",
    "                  left_on=['origin_airport_id', 'fl_month'], \n",
    "                  right_on=['origin_airport_id', 'fl_month'],\n",
    "                  suffixes=('_', '_origin')).merge(features_8,                                \n",
    "                  left_on=['holidate', 'origin_airport_id', 'dest_airport_id'], \n",
    "                  right_on=['holidate', 'origin_airport_id', 'dest_airport_id'],\n",
    "                  suffixes=('_', '_holidate')).merge(features_9,                               \n",
    "                  left_on=['origin_airport_id', 'dest_airport_id', 'fl_dayofweek'], \n",
    "                  right_on=['origin_airport_id', 'dest_airport_id', 'fl_dayofweek'],\n",
    "                  suffixes=('_', '_route'))\n",
    "    \n",
    "    # dropping irrelevant columns\n",
    "    train_y = train_df['target_delay']\n",
    "    \n",
    "    train_X = train_df.drop(columns = ['op_unique_carrier',\n",
    "                       'tail_num',\n",
    "                       'origin_airport_id',\n",
    "                       'dest_airport_id', 'target_delay',\n",
    "                                       'fl_month',\n",
    "                                      'fl_dayofweek'])\n",
    "    \n",
    "    return train_y, train_X\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def preparing_test_dataset(df):\n",
    "    \"\"\"Input: 'raw' testing dataframe from csv file\n",
    "    This function takes the raw pd.read_csv('flights_test.csv') \n",
    "        applies the engineered feature aggregations\n",
    "        and restructures it to the form it needs to be \n",
    "        for Scaling and Model Predicting\n",
    "    Output: X_test. \n",
    "    \"\"\"\n",
    "    \n",
    "    ######################################################\n",
    "    # getting the list of US national holidays\n",
    "    # run this if 'holidays' is not available. check the file location first\n",
    "    try:\n",
    "        us_holidays_df = pd.read_csv('../extra/us_holidays.csv')\n",
    "    except:\n",
    "        filname = input('File location for us_holidays_df')\n",
    "        us_holidays_df = pd.read_csv(filname)\n",
    "\n",
    "    from datetime import timedelta\n",
    "    holidays = []\n",
    "    for hol in us_holidays_df['date'].values:\n",
    "        holstart = pd.to_datetime(hol) - timedelta(days=5)\n",
    "        holend = pd.to_datetime(hol) + timedelta(days=3)\n",
    "        holidayweek = pd.date_range(holstart, holend)\n",
    "        holidays.extend(holidayweek)\n",
    "    #######################################################   \n",
    "    \n",
    "    # column transformations to integrate with the preprocessed feature tables:  \n",
    "\n",
    "    # binarize branded share\n",
    "    df['branded_share'] = df['branded_code_share'].apply(lambda x: 1 if len(x)>2 else 0)\n",
    "    # extract month and day of week and holidate\n",
    "    df['fl_date'] = pd.to_datetime(df['fl_date'])\n",
    "    df['fl_month'] = df['fl_date'].dt.month\n",
    "    df['fl_dayofweek'] = df['fl_date'].dt.dayofweek\n",
    "    df['fl_date'] = pd.to_datetime(df['fl_date'])\n",
    "    df['holidate'] = df['fl_date'].apply(lambda x: 1 if x in holidays else 0)\n",
    "     # extract flight hour\n",
    "    df['dep_hour'] = (np.round(df['crs_dep_time'],-2)/100).astype(int)\n",
    "    df['arr_hour'] = (np.round(df['crs_arr_time'],-2)/100).astype(int)   \n",
    "    # drop irrelevant columns   \n",
    "    df.drop(columns = ['dup', 'mkt_unique_carrier', 'mkt_carrier',\n",
    "                         'mkt_carrier_fl_num',\n",
    "                         'op_carrier_fl_num',\n",
    "                         'origin', 'origin_city_name',\n",
    "                         'dest', 'dest_city_name',\n",
    "                         'crs_elapsed_time',\n",
    "                         'flights',\n",
    "                            'fl_date',\n",
    "                            'crs_dep_time', 'crs_arr_time',\n",
    "                         'branded_code_share'],\n",
    "              inplace=True) \n",
    "    \n",
    "    ################# calling features tables\n",
    "    \n",
    "    # merging the testing dataset with the features tables of aggregate values\n",
    "    # thereby converting categorical and ordinal columns to continuous values\n",
    "    tmp = df\n",
    "    df = tmp.merge(features_features_2, \n",
    "                  left_on=['tail_num'], \n",
    "                  right_on=['tail_num'], how='left').merge(features_features_3,\n",
    "                  left_on=['tail_num','dep_hour'],\n",
    "                  right_on=['tail_num','dep_hour']).merge(features_features_4,\n",
    "                  left_on=['tail_num','arr_hour'],\n",
    "                  right_on=['tail_num','arr_hour']).merge(features_features_5,\n",
    "                  left_on=['op_unique_carrier', 'branded_share', 'fl_dayofweek'], \n",
    "                  right_on=['op_unique_carrier', 'branded_share', 'fl_dayofweek'],\n",
    "                  suffixes=('_', '_carrier')).merge(features_features_6,\n",
    "                  left_on=['dest_airport_id', 'fl_month'], \n",
    "                  right_on=['dest_airport_id', 'fl_month'],\n",
    "                  suffixes=('_', '_dest')).merge(features_features_7,\n",
    "                  left_on=['origin_airport_id', 'fl_month'], \n",
    "                  right_on=['origin_airport_id', 'fl_month'],\n",
    "                  suffixes=('_', '_origin')).merge(features_features_8,                                \n",
    "                  left_on=['holidate', 'origin_airport_id', 'dest_airport_id'], \n",
    "                  right_on=['holidate', 'origin_airport_id', 'dest_airport_id'],\n",
    "                  suffixes=('_', '_holidate')).merge(features_features_9,                               \n",
    "                  left_on=['origin_airport_id', 'dest_airport_id', 'fl_dayofweek'], \n",
    "                  right_on=['origin_airport_id', 'dest_airport_id', 'fl_dayofweek'],\n",
    "                  suffixes=('_', '_route'))\n",
    "    \n",
    "    df.drop(columns = ['op_unique_carrier',\n",
    "                       'tail_num',\n",
    "                       'origin_airport_id',\n",
    "                       'dest_airport_id',\n",
    "                       'fl_month',\n",
    "                       'fl_dayofweek'],\n",
    "              inplace=True)\n",
    "\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561e6e1f",
   "metadata": {},
   "source": [
    "## Step 1: Testing on a sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06745654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload full dataset\n",
    "chunk = pd.read_csv('../datasets/flights_train_set.csv', \n",
    "#                     usecols = usecols, \n",
    "                    chunksize=1000000, \n",
    "                    low_memory=False)\n",
    "df_full = pd.concat(chunk)\n",
    "df_full.drop(columns = 'Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62ab33d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the features generated by aggregating the dataset values\n",
    "\n",
    "features_2 = pd.read_csv('../data/features_tailnum_delay_taxi_multiclass_params.csv')\n",
    "features_3 = pd.read_csv('../data/features_tailnum_hourly_delays_multiclass_params_dep.csv')\n",
    "features_4 = pd.read_csv('../data/features_tailnum_hourly_delays_multiclass_params_arr.csv')\n",
    "features_5 = pd.read_csv('../data/features_carrier_branded_dayofweek_delay_multiclass_params.csv')\n",
    "features_6 = pd.read_csv('../data/features_dest_monthly_multiclass_params.csv')\n",
    "features_7 = pd.read_csv('../data/features_origin_monthly_multiclass_params.csv')\n",
    "features_8 = pd.read_csv('../data/features_holiday_multiclass_params.csv')\n",
    "features_9 = pd.read_csv('../data/features_origin_dest_route_dayofweek_multiclass_params.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4840825f",
   "metadata": {},
   "source": [
    "### Preparing the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be230e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a sample\n",
    "df_sample = df_full.sample(n=3000000)\n",
    "\n",
    "# getting the target and value datasets\n",
    "tmp_train_batch = preprocessing_dataset(df_sample)\n",
    "y_batch, X_batch = preparing_training_df(tmp_train_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bbf18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_batch.shape, X_batch.shape # check shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c6dacb25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "carrier_delay          899283\n",
       "late_aircraft_delay    226275\n",
       "nas_delay              176796\n",
       "weather_delay           19601\n",
       "security_delay            955\n",
       "Name: target_delay, dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_batch.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28c489b",
   "metadata": {},
   "source": [
    "Due to the unbalanced classes, we have to strategically create sample data for training.\n",
    "\n",
    "We will try 2 strategies: \n",
    "\n",
    "1. underbalancing the bigger classes or \n",
    "\n",
    "2. overbalancing the smaller classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7c7cde9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating filters for the target classes\n",
    "Y_carrier = y_batch == 'carrier_delay'\n",
    "Y_aircraft = y_batch == 'late_aircraft_delay'\n",
    "Y_nas = y_batch == 'nas_delay'\n",
    "Y_weather = y_batch == 'weather_delay'\n",
    "Y_security = y_batch == 'security_delay'\n",
    "\n",
    "# to get the indices of the records\n",
    "y_carrier_index = y_batch[Y_carrier].index\n",
    "y_security_index = y_batch[Y_security].index\n",
    "y_nas_index = y_batch[Y_nas].index\n",
    "y_weather_index = y_batch[Y_weather].index\n",
    "y_aircraft_index = y_batch[Y_aircraft].index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7081987",
   "metadata": {},
   "source": [
    "#### 1. underbalancing the bigger classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "25133337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize the sample size of the classes so they're equal\n",
    "y_security_training_index = y_security_index\n",
    "y_nas_training_index = np.random.choice(y_nas_index, size = 324)\n",
    "y_weather_training_index = np.random.choice(y_weather_index, size = 324)\n",
    "y_carrier_training_index = np.random.choice(y_carrier_index, size = 324)\n",
    "y_air_training_index = np.random.choice(y_aircraft_index, size = 324)\n",
    "\n",
    "\n",
    "# add them together and shuffle\n",
    "shuffle_index = np.concatenate((y_security_training_index,\n",
    "                  y_nas_training_index,\n",
    "                  y_weather_training_index,\n",
    "                  y_carrier_training_index,\n",
    "                  y_air_training_index))\n",
    "np.random.shuffle(shuffle_index)\n",
    "np.random.shuffle(shuffle_index) # to be doubly sure\n",
    "\n",
    "# make X, the parameters based on the shuffle_index\n",
    "\n",
    "X_train = X_batch.iloc[shuffle_index]\n",
    "y_train = y_batch.iloc[shuffle_index] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "87939dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "security_delay         955\n",
       "late_aircraft_delay    324\n",
       "carrier_delay          324\n",
       "nas_delay              324\n",
       "weather_delay          324\n",
       "Name: target_delay, dtype: int64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705713ae",
   "metadata": {},
   "source": [
    "**Note**: That a separate test_dataset was reserved before feature generation to avoid data leak. So we will not be using `train test split` to split off from the training dataset, but collecting our test data from a portion of the original `flights.csv` file that was split off before the aggregations were generated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5597ad",
   "metadata": {},
   "source": [
    "### Preparing the testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7a4b16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare test data with train test split\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.20, random_state=88)\n",
    "\n",
    "test_full = preprocessing_dataset(pd.read_csv('../datasets/flights_test_set.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9a7a2e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2251, 59), (277996, 59), (2251,), (277996,))"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batch = test_full\n",
    "y_test, X_test = preparing_training_df(test_batch)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape # checking they're shaped the same way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "29845824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "carrier_delay          189444\n",
       "late_aircraft_delay     47703\n",
       "nas_delay               36659\n",
       "weather_delay            3990\n",
       "security_delay            200\n",
       "Name: target_delay, dtype: int64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts() # checking that it has all the labels we need"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a546b8b1",
   "metadata": {},
   "source": [
    "* Now that the datasets are ready, model training and testing starts here...\n",
    "* Our first model is Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "66746194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1500, random_state=88)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1500, random_state=88)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1500, random_state=88)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scale the data\n",
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_scaled = scaler.transform(X_train)\n",
    "\n",
    "# train model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=88, max_iter=1500)\n",
    "clf.fit(X_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "045303ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21708585735046548"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing the test data\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "clf.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "18002a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "      carrier_delay       0.75      0.18      0.29    189444\n",
      "late_aircraft_delay       0.27      0.33      0.30     47703\n",
      "          nas_delay       0.24      0.25      0.24     36659\n",
      "     security_delay       0.00      0.54      0.00       200\n",
      "      weather_delay       0.04      0.27      0.07      3990\n",
      "\n",
      "           accuracy                           0.22    277996\n",
      "          macro avg       0.26      0.31      0.18    277996\n",
      "       weighted avg       0.59      0.22      0.28    277996\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18008ef4",
   "metadata": {},
   "source": [
    "#### 2. overbalancing the smaller classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "75b86660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "carrier_delay          899283\n",
       "late_aircraft_delay    226275\n",
       "nas_delay              176796\n",
       "weather_delay           19601\n",
       "security_delay            955\n",
       "Name: target_delay, dtype: int64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_batch.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c939be5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize the sample size of the classes so they're equal\n",
    "y_carrier_training_index = y_carrier_index\n",
    "# y_nas_training_index = np.random.choice(y_nas_index, size = 102820)\n",
    "# y_weather_training_index = np.random.choice(y_weather_index, size = 102820)\n",
    "# y_carrier_training_index = np.random.choice(y_carrier_index, size = 57791)\n",
    "# y_air_training_index = np.random.choice(y_aircraft_index, size = 57791)\n",
    "# y_nas_training_index = y_nas_index\n",
    "\n",
    "tmp = [] # create an empty list then append rhe class index as many times as needed\n",
    "for i in range (4):\n",
    "    tmp.extend(y_aircraft_index)\n",
    "y_air_training_index = tmp\n",
    "\n",
    "tmp = []\n",
    "for i in range (5):\n",
    "    tmp.extend(y_nas_index)\n",
    "y_nas_training_index = tmp\n",
    "\n",
    "\n",
    "tmp = []\n",
    "for i in range (50):\n",
    "    tmp.extend(y_weather_index)\n",
    "y_weather_training_index = tmp\n",
    "\n",
    "tmp = []\n",
    "for i in range (1000):\n",
    "    tmp.extend(y_security_index)\n",
    "y_security_training_index = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d85b2d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "weather_delay          980050\n",
       "security_delay         955000\n",
       "late_aircraft_delay    905100\n",
       "carrier_delay          899283\n",
       "nas_delay              883980\n",
       "Name: target_delay, dtype: int64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# add them together and shuffle\n",
    "shuffle_index = np.concatenate((y_security_training_index,\n",
    "                  y_nas_training_index,\n",
    "                  y_weather_training_index,\n",
    "                  y_carrier_training_index,\n",
    "                  y_air_training_index))\n",
    "np.random.shuffle(shuffle_index)\n",
    "np.random.shuffle(shuffle_index)\n",
    "# make X, the parameters based on the shuffle_index\n",
    "\n",
    "X_train = X_batch.iloc[shuffle_index]\n",
    "y_train = y_batch.iloc[shuffle_index] \n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d7671789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3535230722744212"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scale and train model\n",
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_scaled = scaler.transform(X_train)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=88, max_iter=1000)\n",
    "clf.fit(X_scaled, y_train)\n",
    "\n",
    "# testing the test data\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "clf.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b22b8ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "      carrier_delay       0.78      0.35      0.48    189444\n",
      "late_aircraft_delay       0.27      0.40      0.32     47703\n",
      "          nas_delay       0.24      0.33      0.28     36659\n",
      "     security_delay       0.00      0.28      0.00       200\n",
      "      weather_delay       0.04      0.38      0.06      3990\n",
      "\n",
      "           accuracy                           0.35    277996\n",
      "          macro avg       0.27      0.35      0.23    277996\n",
      "       weighted avg       0.61      0.35      0.42    277996\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addbe3f8",
   "metadata": {},
   "source": [
    "## Step 2: Testing on the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfe1325b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4877259,),\n",
       " (4877259, 59),\n",
       " carrier_delay          3306244\n",
       " late_aircraft_delay     845768\n",
       " nas_delay               650651\n",
       " weather_delay            71051\n",
       " security_delay            3545\n",
       " Name: target_delay, dtype: int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get full\n",
    "df_sample = df_full\n",
    "\n",
    "# getting the target and value datasets\n",
    "tmp_train_batch = preprocessing_dataset(df_sample)\n",
    "y_batch, X_batch = preparing_training_df(tmp_train_batch)\n",
    "y_batch.shape, X_batch.shape, y_batch.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e038a3",
   "metadata": {},
   "source": [
    "(What happened?! Why is the dataset so small? Because this model is trained on the sample of flights that have already been delayed. Only a small portion of the entire 16M flights were actually delayed flights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63b1a256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# once again, we have to overbalance the smaller classes...\n",
    "# creating filters for the target classes\n",
    "Y_carrier = y_batch == 'carrier_delay'\n",
    "Y_aircraft = y_batch == 'late_aircraft_delay'\n",
    "Y_nas = y_batch == 'nas_delay'\n",
    "Y_weather = y_batch == 'weather_delay'\n",
    "Y_security = y_batch == 'security_delay'\n",
    "\n",
    "# to get the indices of the records\n",
    "y_carrier_index = y_batch[Y_carrier].index\n",
    "y_security_index = y_batch[Y_security].index\n",
    "y_nas_index = y_batch[Y_nas].index\n",
    "y_weather_index = y_batch[Y_weather].index\n",
    "y_aircraft_index = y_batch[Y_aircraft].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5555eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "weather_delay          3552550\n",
       "security_delay         3545000\n",
       "late_aircraft_delay    3383072\n",
       "carrier_delay          3306244\n",
       "nas_delay              3253255\n",
       "Name: target_delay, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resize the sample size of the classes so they're equal\n",
    "y_carrier_training_index = y_carrier_index\n",
    "# y_nas_training_index = np.random.choice(y_nas_index, size = 102820)\n",
    "# y_weather_training_index = np.random.choice(y_weather_index, size = 102820)\n",
    "# y_carrier_training_index = np.random.choice(y_carrier_index, size = 57791)\n",
    "# y_air_training_index = np.random.choice(y_aircraft_index, size = 57791)\n",
    "# y_nas_training_index = y_nas_index\n",
    "\n",
    "tmp = [] # create an empty list then append rhe class index as many times as needed\n",
    "for i in range (4):\n",
    "    tmp.extend(y_aircraft_index)\n",
    "y_air_training_index = tmp\n",
    "\n",
    "tmp = []\n",
    "for i in range (5):\n",
    "    tmp.extend(y_nas_index)\n",
    "y_nas_training_index = tmp\n",
    "\n",
    "\n",
    "tmp = []\n",
    "for i in range (50):\n",
    "    tmp.extend(y_weather_index)\n",
    "y_weather_training_index = tmp\n",
    "\n",
    "tmp = []\n",
    "for i in range (1000):\n",
    "    tmp.extend(y_security_index)\n",
    "y_security_training_index = tmp\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "# add them together and shuffle\n",
    "shuffle_index = np.concatenate((y_security_training_index,\n",
    "                  y_nas_training_index,\n",
    "                  y_weather_training_index,\n",
    "                  y_carrier_training_index,\n",
    "                  y_air_training_index))\n",
    "np.random.shuffle(shuffle_index)\n",
    "np.random.shuffle(shuffle_index)\n",
    "# make X, the parameters based on the shuffle_index\n",
    "\n",
    "X_train = X_batch.iloc[shuffle_index]\n",
    "y_train = y_batch.iloc[shuffle_index] \n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd90932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale and train model\n",
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_scaled = scaler.transform(X_train)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=88, max_iter=1000)\n",
    "clf.fit(X_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0fa6266d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23565171586319916"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing the test data\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "clf.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1a45c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "      carrier_delay       0.77      0.16      0.27    174097\n",
      "late_aircraft_delay       0.28      0.41      0.33     44522\n",
      "          nas_delay       0.24      0.36      0.28     33842\n",
      "     security_delay       0.00      0.43      0.00       182\n",
      "      weather_delay       0.03      0.39      0.06      3642\n",
      "\n",
      "           accuracy                           0.24    256285\n",
      "          macro avg       0.26      0.35      0.19    256285\n",
      "       weighted avg       0.60      0.24      0.28    256285\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fb5c26",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cc9ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale and train model\n",
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_scaled = scaler.transform(X_train)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(random_state=0)\n",
    "rfc.fit(X_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daf5357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the test data\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "y_pred = rfc.predict(X_test_scaled)\n",
    "rfc.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadd233c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa7f24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147d637c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f234c66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2d05a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86618046",
   "metadata": {},
   "source": [
    "## Model: Naive Bayes GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0fc08912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.028807772596913594"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scale and train model\n",
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_scaled = scaler.transform(X_train)\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Build a Gaussian Classifier\n",
    "nbG = GaussianNB()\n",
    "\n",
    "# Model training\n",
    "nbG.fit(X_scaled, y_train)\n",
    "\n",
    "\n",
    "# testing the test data\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "nbG.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "903b8e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "      carrier_delay       1.00      0.00      0.00    174097\n",
      "late_aircraft_delay       0.25      0.00      0.00     44522\n",
      "          nas_delay       0.23      0.15      0.18     33842\n",
      "     security_delay       0.00      0.63      0.00       182\n",
      "      weather_delay       0.02      0.62      0.04      3642\n",
      "\n",
      "           accuracy                           0.03    256285\n",
      "          macro avg       0.30      0.28      0.04    256285\n",
      "       weighted avg       0.75      0.03      0.02    256285\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = nbG.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ecee5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaf3394",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b1437f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31e4092",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
